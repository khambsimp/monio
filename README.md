# monios 0.0.1
The fully functional Operating System.

A refreshed OS with a different approach to utilize Theory of Computing
to develop a blueprint of a Computer Architecture that is beneficial to the society of the future.

The way that Software and Computer development is done does not actually take into consideration how people have developed and grown their understanding of computing in particular, or information in general. A common misconception might be our tendency to expect current conceptualizations of computing to be lead by the needs of scientists, when many of the greatest applications of computing may be initiated from people outside of science. This is a conceptualization of computing as a concept more broad and able to impact society at a greater magnitude.

# Language
We begin our study of Computing with an interrogation. Is the way language is manifested within our cognition similar between people? The way that language tends to accomodate abstract concepts is similar enough that we should question why. When authors write literature they interrogate the English lexicon to build their world. Oftentimes pulling from phrase, or parable. In a similar way when architects develop architecture, or programming language designers develop communication that can be codified in binary form we benefit from their abstractions. In a similar way,  interrogating the abstractions applied to computing can impact the way we consider encoded language. For this reason generative grammar, vedic grammar, and goedel's parable seem to interrogate why people engage in linguistic abstraction. Language, by being discernable and uniform requires a kind of structure, but without the ability to accomodate abstraction feels incomplete. What do language abstractions share
in common?

The independent development of written language has occurred only four times in recorded history. And as such we are hesitant to develop new symbolic languages unless forced to by societal factors. In a similar way it is often societal factors which initiate our retreat to our so basic of instincts with the desire to start again. Therefore, it is amazing that information theory has brought us to examine this underpinning of understanding again. Within the realm of linguistics, and more specifically written, symbolic language, we find that to interrogate certain facilities within language, and to promote the development of intertwined systems which are persistent, developing, and the design of symbolic logics are pertinent. Algebra and Algorithms, the most familiar of these, have been studied for Millennia. However, as the systems which people develop become more interconnected, so does our use of symbolism, and our implementation of natural language. We utilize logic symbolism to develop arguments that can persist over time. When we seek a language to discuss magnitudes, we aim to define symbolically the repeated behavior people tend to utilize when studying decidable patterns within quantitative language. We aim to define a language which can be expanded to repeated symbols. The language elements which maintain their decidability are also elements of study.

The implications of a logic language which can be expressed as a subset of a natural language construes natural languages as musical expressions. A logic is focused on expressing a subset of language that is focused on truth. As a mathematical, or scientific expression, this can be expressed as an objective argument written from a perspective which is simple to follow, and where assumptions of axioms have been formally expressed. All natural language contains a subset within expression, which can be utilized to develop these specific kinds of arguments. Formally developing a subset of symbols to express these arguments is also possible, and aids the the formal representation of argument. In another sense these, formal expressions utilized to develop arguments are a type of mathematics isf they refer to quantititave arguments or quantitiative analysis. In the case they are used to refer to discrete systems or natural language arguments they are called formal languages. These are the prescursor to programming languages, including Hardware Desciption Languages and Theorem Solving Systems. This suggests that logic gates cannot only be designed from a formal perspective creating common logic units, instead they can actually be developed like a theortical proof to accomodate a set of particular arguments, as a derivative of formalized axioms.

# Computing Paradigms
## Personal Computing
There are similarities in the way that human beings comprehend computers. In essence, it amounts to how we architect information in a way that it can be processed correctly, and computably using logic, arithmetic, and integer math. To process large swathes of information we tend to develop abstractions. These abstractions can be deduced to amount to logic, arithmetic, and integers when analyzed and optimized. However, we use abstractions to communicate with other humans, based on the specific way the computable functions have been implemented in physical reality. This project address how, our theoretical, and mathematical conceptualizations of computing affect, the implemented and as designed languages, and processors used to store and compute the information within our lives. Games. To an extent the gamification of programming does respect an aspect of how information and knowledge fundamentally accumulage within society. From an architectural standpoint we have tendencies to develop information like legos. Fundamentally, what makes computability and recursion so alluring is the idea they
would enable us to develop a systematic information framework, that like loading a sonic game on gamecube, would first load this history and language framework we were familiar with, in the case Nintendo, and then within that framework be amble to navigate within an existing framework of a menu and levels, and where we would have a simple instrument or interface, be it a gamecube controller, or in this case a keyboard and command line interface. Either way people can create for themselves a small universe they can make isolated changes within. This is key, small insulated changes, which although deliberate lead to an outcome we can measure. The confidence this inspires is immense. It feels like sonic superpowers. Also text generation on all devices mobile and personal goes a long way in developing the variety of mediums people can use to develop high quality text, and instructions. This will be remedied in time. In any case, being able to make changes builds confidence in a person to consistently make changes to a worldwide database over time. Slowly steering the accumulation of information itself. It is important to preserve this interface, such that people everywhere are able to write and impact the development of society, in their own way
and at their  own pace. The cursor placement is placed at the gaihorizon of our collective future.

## Cloud Computing
A great resource on this end, is the aptly name Warehouse Scale Computer. In the future this may actually resemble a Pwer Station, but should also be coupled witht he ability to devleop distributed ways for people to devleop their own power and run their own Servers. Computing has been framed in terms of size (volume), weight (mass), and power (energy) as quantitative design elements for an efficient computing platform. Lo and behold these tradeoffs are not unique to warehosue scale computers themselves. On the contrary, computing and its operations at scale are often framed in reference to time, or energy (resource) efficiency. In other words, as people build larger and larger computing platforms, we also find that large scale building renditions of these must also operate efficiently in order to justify the resources used to develop them. In other words computing paradigms are not only important for their impact, and reframing of information, but also their efficiency.

How do operations and energy reformat and codify large amounts of information and data?
Theory of Computation, Computability Theory, Complexity Theory, Algorithms and Data Structures,  Automata Theory, Discrete Mthematics
Is this reformatting effective to society? Universally available?

## Distributed Computing
One oft he most prevalent examples of the appliacbility of distributed version control systems is the outcome of the programming tool git.
Git enables information to be communicated across many discrete processing systems near simultaneously in terms of Network speed. At the final
computing instance, when developed on a general purpose processor, on a general pupose computer, general purporse operating system, and in a general pupeose languege, lets assume an ABI compatibility here. Then there is is a binary replication fo the underlyign environment possible.

The goal of Monoid Internet is to explore what an information minicomputer could be. The question at hand is, is there a better way to design computers than the method we are using right now? The answer is probably yes. Computers are information manipulators at their core, so programming can really look however we would like it to. It more so depends on the outcome you're looking for.

When developing an architecture to describe how computers can maintain network synchronized information, it's important to develop a framework, which can span from two individual computers to many. An information format which both encodes network properties, and transposes oncoming data. This is similar to JSON binary format. One could imagine a scenario were the Network encoding defined for transmission across a Wired, or Wireless Networking protocol, Global Network Transmission would seem near real time, including in the scenario of a Database.

The information computer is also vital for determining how to codify, and distribute algorithmic encoders which can develop information architecture efficiently. For instance Git is a form of radio, it is capable of sitting as an https endpoint on a host computer, and store the eventual commits of thousands of developers asynchronously. This enables programmers to develop software architecture concurrently, in a parallel fashion, and asynchronously.

# Programming Language Paradigms

# A Computer is a Mathematical Construct
## Logic
Human Beings can reason about Computers, and communicate their reasoning to one another with a high degree of fidelity. Human Beings develop written symbolic languages which from amathematical perspective can represent the state of an Information System with Symbolic precision. There are particular definitions of a set that represent all Discrete formulations of a Computing problem. Computers (Boolean Operators) and (Turing Complete Languages). Now these logical preceptors are also computability operators, and information encoders in the language argument and framework sense. What does a language which can be proved actually gain you? Does it mean you can use less symbols and definitions, once the axioms of said language are defined, does it mean that there are provable statements which are not apparent within the language that would be provable otherwise? Let's say, types, sets, and proofs are the logic language equivalents to a transitor, or to a single neuron. In this viewpoint, artificial automata, and biological automata, and written syntactic automata could model systems of comparable complexity. One of the best ways for people to manage large scale complexity is to develop symbolic logic that can describe or model interconnected systems, and then relate that to natural language.

So what have you humble learned about Logic? Well I have learned that logic is an administering of a context to natural language in such way that it is resonable to expect that it could preserve truth in a way that its symbols could be expressed recursively. the two language frameworks where we most often encounter these are within mathematics and computer science. This is because for these two language families to be highly effective in describing a variety of phenomena utilizing recursive language is one of the most effective ways to do so.

Can Deductive reasoning and recursion be used to develop understanding in other areas of Science. The growth of Logic Notations of which Programming Languages are a single instance of suggests this is currently administered to knowledge of our current age.In the field of Digital Logic Circuit Design, we see a direct application of Symbolic Logic Theory, including in their application to Hardware Description Languages as an example. It is also important that
in the case where an aspect of cognition can be written with its own symbology which also has recursive properties that this is imprtant for understanding both mathematics and logic from a cognitive perspective. That being Symbolic Logic Theory. Logic can be approached from a Philosophical, Linguistic, and Mathematical perspective. In terms of Programming Language Theory we are able to use any which aids our particular purpose of defined terms. Currently Typer Theories and Homotopy Type Theory seems to be the most applicable to dveevelopment of Hardware Desciption Languages.

What is the role of a Logician in the Semicondictor industry?
The role of the logician is to develop and to distribute languages that can be used in a technical fashion.

## Homotopy Type theory
Homotopy Type Theory can be utilized to develop instruction set architectures, and microcontrollers using a Hardware Description Language, this can be utilized to develop Microcontrollers which are far simpler in design, and can be reasoned and verified using modern tools without the design verification being reasoned about by the Chip designer. Not to the extent that designers are expected to today. Logicians are particularly impact by this developments of Logic Languages, which can serve as foundatiosn for mathematics for the reason that Information Systems which are defined on a mathematical premise are often scalable. This scalability means that when these architectures are implemented or applied in a large scale integration or manaufacturing capacity that general pupose architectures can be developed which incorporate an ability to recieve and transmit a variety of discrete and continuous signals. Making these architectures, versatile, yet also low power, yet also enable people to veridy and quantify the performance of a particular design versus another before a full manufacturing process has been developed.

## Discrete Mathematics
Discrete Mathematics is a logical, quantitative basis for scalable Algorithms and Computer Science in general. Programmers require a foundational framework to reason about Computers, Data, Information, and Networks. Discrete Mathematics tends to focus on, and provide useful techniques for scalable constructs useful within a context of Computing. Programmers can program natural numbers and integers reflexively.
## Algorithms
Or Algebra designated for Discrete Mathematics, abstracts different approaches to define discrete functions using variables. Algebra and Algorithms are intimately related. Algorithms and Algorithmic Analysis institute a formal way to estimate the performance of a program using analytic methods. algorithmic Analysis is ever more important. Similar to Real Analysis, Algorithmic Analysis presents a number of techniques from Applied Complexity Theory, Applied Programming Language Theory, and Applied Automata theory to derive and compare the real world performance of Algorithms and Data Structures. To what extent can we determine the expected as implemented program to run in finite time or energy. To what extent do these match performance of engineered Computers?
## Data Structures
Oftentimes to define efficient algorithms a symbolic representation must be created for both the algorithm and the data it operates upon.  When Algorithmic Analysis is applied to large scale programs, the problem of how memory and data are accessed impact the performance of a program and its scalable nature.
## Cryptography
Cryptography includes the preservation of information across physical spaces and in the event that data has been corrupted intentionally, this is especially important in proving the validity of data within networks.
## Programming Language Theory
Programming Language theory includes the development of natural language shorthand that is related Turing machines which operate on discrete systems in a way which people can reason about them. Programming Language Paradigm how suseful or not are they?
## Homotopy Type Theory
## Type Theory
Type Theory is a Logic  Language created to further abstract the consolidation of language within a programming language, making complex functions succint in their description of off nominal notions. The type theory referenced here is more directly applicable to Martin Lowe Type Theory or Intuitionistic Type Theory, and is applied in Discrete Mathematic forum by way of Homotopy Type Theory. Homotopy Type Theory has found its way into Theorom Solvers an Program Type where it has been successful informalizing notions of proof based on Conjecture, and Hypothesis. This is
## Formal Languages
Formal Languages are logic languages more related to shorthand logic and discrete notions with a natural language.
## Theory of Computation
Theory of Computation is large collection of organized methods for using number theory to describe the construction and description of large computable and realizable systems that can be reasoned about to the same magnitude. Theory of Computation derrides a few fundamental changes in aspects and approaches for the development of computing resources. These include the Theory of Cmputations, Computability Theory, Automata Theory and Complexity Theory. Theory of Computation encompasses our methods of making computing, simpler, more time and energy efficient, and easier for programmers to express.
## Computability Theory
This concerns where and to what extent ever more complex computable languages can be written. One could imagine a case where, even though, a particular abstract argument about computing large scale data were made, the impediment to actually simulate an appropriate calculation would be the framework, or basis language of the computation. That is, when given a set of computable rules, a Computer can distill an argument in abstract human terms. The language and whether the recursive process is definable within the computer language makes computability a conscious abstract solution to a posed data analysis. If it is impossible to define a computing language that can distill whether any mathematical statement were true or false, what is the minimum number of rules and guidance that should be made so that a computer or definable language could determine the extent to which a  mathematical statement is correct or false?
## Complexity Theory
In essence Computing is an excersize in managing Complexity. As Software projects grow, so do the number of referenced helper libraries, and related extractions used to limit the processing involved to provide a usable software definition. As the number of dependencies grow for sophisticated software frameworks, so does the possibility that a dependent element may break or be infected by malware. Languages must be both expressive, yet also maintain their operating intent regardless of how the algorithm is framed. Encoding functions must conversely not be described by equally complex and dependent software entities. The Art of managing Complexity, Systems Theory, and Architecture are all exercises in managing and scaling Simplicity. In a real sense when Computers do not scale, Complexity has masked the underlying intent of the Program. Famous problems include P=NP and this theory is linked directly to the field of Cryptography.
## Systems Theory
Systems Theory constitutes the techniques people use to manage Complexity within real world applied systems. At the same time it constitutes the difficult in arranging multiple involved disciplines, and managing interactions that are not logically definable in an immediate sense, think the Halting Problem within Computability Theory. Systems is a method of defining a workflow, to provide the best possible chance to develop within the limit of a "Halting Problem" whilst still being able to nogotiate between a usable system, and one which is not. One of the most predominant problems in Computer development today is developing an environment which is binary compatible between different general purpose computing instatiations. The second, is once a similar environment has been defininded how are changes at different computing instantiations made independently such that improvements in oreder of magnitude, or in order of multitude are possbilt to conserve the overall systems net energy usage, timing, or sumber of elements required symbolically to preserve its complex performance? Were Computing a design and architecture problem, then presumably by developing the optimum way to express a design such that the most efficient performance is achievable would consitute a Science where by quatification would suggest the most efficient designs possible given basic axioms are arguments about the development of the consittuent Automatons.
## Graph Theory
Graph theory is closely related to Network Theory and the development of nodes with an emphasis of how they related to one another instead of what their value is individually. Graphs are useful for modeling dependent relationships between a single entity and its m=peers. For Peer to Peer Computing, Graphs may relate the interdependent relationships between data members. For protocol engineering the network itself may track relationships between entities, however this may be information which can be tracked only within the near term.
## Automata Theory
Automata Theory and Turing Machines are class of entities utilized by Computer Scientists, and Formal Language Theorists to reason about the performance of Algorithms. That is when algorithms are applied, there are aspects of their behavior which are limited in time, and or memory, that Automata are able to model in Discrete form. Notable as well is that, the way that sciety seems to be developing would suggest that Automata are becoming more a framework for building and developing Computers that Computers themselves. In a world where Automata are prevalent, it becomes more prfound action to prgram them and issue them in a way which is decisive.
## Cybernetics
Cybernetics more colesely involves the interplay between the human and the machine. The extent to which bilogical entities en masse may adhere to or organize themselves in mechanistic ways to be efficient as a system. This is important within the context of Automata, because, Automata are regulat in their construction, and in the way that they interpret language. To be able to coordinate many Automata also invovles a certain understaing of both language and they way that Complex Systems tend to evolve, especially in their tendancy to reach a state of survival.
## Information Theory
At its core the study of Information concerns Human Beings, and the source of their Language capabilities. Human Beings have developed Language over time to to develop written, auditory, handsignal, and other renditions of language which can be percieved by their senses. Lingustics, natural language, math, are all attemps by people to codify and extend their senses and consitiutue ad physical rendition of information. An information which does not only rever to Natural Phenomena but, may refer to aspects of human creativity, history, folklore, and abstract. Information Theory constitutes the until now understanding of how information can be perserved and communicated to human beings, and the extent to which we can construe and perserve language over time,
and communicate it with precision.
## Coding Theory
One of the great efficiencies in Computer Science is being able to say a lot with a little. That is not to just optimize processing, but to determine what and why information in particular should be processed in the first place. In a sense Computer Scientists analyze their framing of a problem in the same way they are adept at picking out to to use when working on a particular one. The Art of Programming is an exercise in Coding Theory. We aim to take information presented, and from it generate an equivalent representation. How that encoding is done is the Art.
One way to express this concept of coding theory is the aliteration between the languages of logic, mathematics, programming languages, and science. In order to understand the language of information we look for patterns, to express those patterns in a scalable manner, we develop algorithms to express them, to document and argue with greater society we develop papers, which are in turn framed in an argumentative manner.
## Communication Theory
Communication Theory includes methods or techniques to derive ways to encode language systems within one another. A great example is in terms of definifng integers, it is known that integers can essentially be encoded or written in terms of any other integer greater than intself. However, utilizing concepts of promes or of even and odd numbers it becomes more worthwhile to encode certain integers in terms of one another using mathematical properties of integers to decrease the amount of information or bits required to define the number itself.
## Category Theory
Category Theory is a method, for categorizing relationships between different field and implementations of math. Fields of Math which seem different often have known methods for converting or applying constituent objects with one another. Category theory provides a set of common techniques to do so, while simplifying, and making more understandable, applications of proofs using different kinds of mathematics. Part Systems language, and part programming language for mathematics. Category Theory is considered an approach of mathematics which can serve as a common language for math.
## Group Theory
Group Theory, similar to category theory is thought of as a possible common language for mathematics, and involves the unifying of fields which seem dissimilar. Groups constitute different objects within mathematics, which can serve as a data structure to organize common objects utilized to define mathematical fields, and their interaction.
## Combinatorics
## Machine Learning
There are a number of techniques for conducting Coding Theory, that is utilizing discrete data to develop codified information of data within multiple layers of abstraction.
## Artifical Intelligence
Artificial Intelligence is form of Digital Filtering involving parallel architectures. These are often described as matrices, however, these are topologically similar to neural nets. These matrices define architectures for storing associations between statistically consistent data, one of these being written speech.
# Science
## Information Science
Incorporates Continuous, Discrete and Statistical Mathematics within a Set theoretic framework to develop concept on how information can be encoded in another mathematican form, and what drawbacks, if any are there to the encoding or decoding process. This also includes the results when these algorithms are implemented are there yields similar? Why or why not?
## Network Science
## Data Science
## Computer Science

# Architecture
## Software Architecture
## System Architecture
## Computer Architecture
What is Computer Architecture and what components of it are remnants of culture or tradition, and which portion is quantitatively supported?
## Chip Architecture
## Instruction Set Architecture
Let us examine instruction set architectures for a moment. Architecture involves an interplay between design, qualitative analysis, quantitative analysis, and language. One of the largest problems in the development of an architecture is how abstract design decisions (information) must be quantitatively analyzed versus one another, then expressed as algorithmic, or pseudo algorithmic language, then the overall archiecture must be typeset, and qualitatively analyzed, and then expressed in as a formal language, which is in turn analyzed with addtional algorithmic languages, at which point the architecture can now be expressed and typeset in qualitative form, as well as have quantitative properties inset. After the Architecure is Typeset it can be expressed as less formal algorithmic languages, and then simulated, thereby generating even more information.
Reduced Instruction Set Architecture, Complex Instruction Set Architecture, Very Long Instruction Word Architecture.

# Industry
## Telecommunications Industry
## Software Industry
## Computer Industry
Generally, how why does engineering feel different to you, and what are you trying to get out of it which is different?
Engineering to me is a creative pursuit where I am trying to determine and explore what is possible though the act of building. How do you know what is possible without actually building it. Many of the most beneficial inventions from a societal stanpoint are complex in terms of integration, hwoever, provide society exponential improvements. As an Engineer, I am exploring the realm of Mathematics, Sciences, exisitng Engineeering, and Existing Technology to look for, and explore ways to propose to society a solution it had not considered before.I don't know the outcome, and choose to mass produce ones where I belive the net benefit it worth the resourse requirement to society and the environment.Sometimes, I don't get to explore all of this but I can begin work, and frame it in a language where others can continue where I left off.

Another reason to Engineer something is for fun, if there is a possibility to develop a technology or computer better, or simpler, or to integrate more human knowledge within it, why not? Even a small scale prototype should be designed to not require massive resources, and should provide people with the ability to test these implications at the small scale first. What technologies do you find fun right now?

One aspect I find fun right now is the question of what is Mathematics? What does it mean to develop Quantitative Analysis? In the grand scheme fo history Quantitiative Analysis has always been useful to people in Design, Architecture, Astronomy, Cosmoplogy, Physics, Chemistry, Biology, Linguistics, Economics, Business, Accounting. It has a whole other meaning today. Historically mathematics was a formulaic, study where few new the methods, and the implementation required rountine implication. That aspect is still true today, however, with the availability of formulae, and the extent to which mathematics has been translated, reiterated, and even branched into a field of Mathematical Analysis, Statistics and its methods, and currently Discrete MAthematics, and its implications to Information and Linguistics, we are living in a world where Quantitiative ANalysis and Athematics, has been grafted to the Philosophical and Logic paradigms of language. Meaning that eh ambiguities within language theory apply to mathematics also. And as such it can take place as fully formable, and abstract language for expression in the way that natual language has since printing, and the dawn of child education. To an extent this means Science itself can be formulated in an equal Quantitative and Qualitatitive footing, even in respect to Social and Biological Sciences, and it also means that existing mathematics and analaysis can be reformulated based on whcih math is able to effectively describe the most important aspects of a problem symbolically.

We are aware that most mathematics can be expressed as a numericalcal and algrbraic calculation, which has implications to Science, Engineering, and Technology, it also helps us understand and give realistic parameters for how a solution might scale when realized.

What does the relation to Set Theory, Type Theory, Homotopy Type Theory buy us? These give us a framework to prove expressions, and ensure that symbology is consistent.

## Semiconductor Industry
## Electrical Industry
# Blog
This is the first instantiation of the monio computer, an information translator. Input is markdown, and this is graphically communicated to the observer through repeated exposure. The direct approach.
## Internet of Things
## Graphic Design System 3
The new Graphic Design System 3 is developed using Non-uniform Rational B-Splines.
























.
